{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "if IN_COLAB:\n",
    "    !git lfs clone https://github.com/sbeeredd04/sandbox_private.git\n",
    "    !cd /content/sandbox_private/ML/Capstone/\n",
    "    sys.path.append('/content/sandbox_private/ML/Capstone/')\n",
    "    #check the current working directory\n",
    "    print(os.getcwd())\n",
    "else:\n",
    "    sys.path.append('..')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set this environment for deterministic execution\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB: \n",
    "    #move to /content/sandbox_private/ML/Capstone/\n",
    "    os.chdir('/content/sandbox_private/ML/Capstone/')\n",
    "    print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpus \n",
    "gpu_ids = \"1,2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_ids\n",
    "\n",
    "print(\"Using GPU IDs: \", gpu_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2: CNN Model for CelebA Multi-Label Classification\n",
    "\n",
    "## Problem Statement\n",
    "Upload a person's image and determine different celebrity attributes they have.\n",
    "\n",
    "## Approach\n",
    "- Multi-label classification using ResNet18 architecture\n",
    "- 40 binary attributes predicted simultaneously  \n",
    "- Custom dataloader for CelebA dataset\n",
    "- Comprehensive evaluation metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Create output directory for plots\n",
    "os.makedirs('celeba_plots', exist_ok=True)\n",
    "print(\"Setup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load CelebA Dataset and Create DataLoaders\n",
    "\n",
    "### Design Justification:\n",
    "- Handles multi-label classification (40 binary attributes)\n",
    "- Supports data augmentation for training\n",
    "- Efficient batch processing\n",
    "- Compatible with PyTorch training pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size and batch size\n",
    "image_size = 128\n",
    "batch_size = 128\n",
    "num_workers = 2\n",
    "data_dir = './data'\n",
    "\n",
    "# Define training transforms with data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Define validation/test transforms without augmentation\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "print(\"Transforms defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Load CelebA datasets with transforms\n",
    "print(\"Loading CelebA datasets...\")\n",
    "\n",
    "try:\n",
    "    # Try to load with download=True first\n",
    "    train_dataset = datasets.CelebA(\n",
    "        root=data_dir,\n",
    "        split='train',\n",
    "        transform=train_transform,\n",
    "        download=True,\n",
    "        target_type='attr'\n",
    "    )\n",
    "    \n",
    "    val_dataset = datasets.CelebA(\n",
    "        root=data_dir,\n",
    "        split='valid',\n",
    "        transform=test_transform,\n",
    "        download=True,\n",
    "        target_type='attr'\n",
    "    )\n",
    "    \n",
    "    test_dataset = datasets.CelebA(\n",
    "        root=data_dir,\n",
    "        split='test',\n",
    "        transform=test_transform,\n",
    "        download=True,\n",
    "        target_type='attr'\n",
    "    )\n",
    "except:\n",
    "    # If download fails, try loading from existing files\n",
    "    print(\"Download failed, attempting to load from existing files...\")\n",
    "    train_dataset = datasets.CelebA(\n",
    "        root=data_dir,\n",
    "        split='train',\n",
    "        transform=train_transform,\n",
    "        download=False,\n",
    "        target_type='attr'\n",
    "    )\n",
    "    \n",
    "    val_dataset = datasets.CelebA(\n",
    "        root=data_dir,\n",
    "        split='valid',\n",
    "        transform=test_transform,\n",
    "        download=False,\n",
    "        target_type='attr'\n",
    "    )\n",
    "    \n",
    "    test_dataset = datasets.CelebA(\n",
    "        root=data_dir,\n",
    "        split='test',\n",
    "        transform=test_transform,\n",
    "        download=False,\n",
    "        target_type='attr'\n",
    "    )\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Total images: {len(train_dataset) + len(val_dataset) + len(test_dataset)}\")\n",
    "\n",
    "# Get attribute names\n",
    "attribute_names = [name for name in train_dataset.attr_names if name.strip()]\n",
    "num_attributes = len(attribute_names)\n",
    "\n",
    "print(f\"\\nNumber of attributes: {num_attributes}\")\n",
    "print(f\"Sample attributes: {attribute_names[:5]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"DataLoaders created with batch size: {batch_size}\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ResNet18 Model Architecture\n",
    "\n",
    "### Model Selection Justification:\n",
    "\n",
    "**Why ResNet18 for CelebA?**\n",
    "\n",
    "1. **Residual Connections**: Skip connections enable training of deeper networks without vanishing gradient issues\n",
    "2. **Proven Architecture**: ResNet18 has demonstrated excellent performance on face recognition tasks\n",
    "3. **Appropriate Depth**: 18 layers provide sufficient capacity for 128x128 face images without overfitting\n",
    "4. **Efficient**: Faster training compared to deeper variants (ResNet50, ResNet101)\n",
    "5. **Multi-label Adaptation**: Final layer modified for 40 binary classifications with sigmoid activation\n",
    "\n",
    "**Strengths:**\n",
    "- Handles vanishing gradients through residual connections\n",
    "- Good generalization on face datasets\n",
    "- Efficient training and inference\n",
    "- Scalable architecture\n",
    "\n",
    "**Weaknesses:**\n",
    "- May struggle with highly correlated attributes\n",
    "- Requires significant computational resources\n",
    "- Needs careful regularization to prevent overfitting on imbalanced attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    # Basic residual block for ResNet18\n",
    "    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        # First convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                              stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                              stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # ReLU activation\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Shortcut connection for dimension matching\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
    "                         stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Save identity for residual connection\n",
    "        identity = x\n",
    "        \n",
    "        # First conv block\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        # Second conv block\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # Add residual connection: H(x) = F(x) + x\n",
    "        out += self.shortcut(identity)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "print(\"BasicBlock defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18MultiLabel(nn.Module):\n",
    "    # ResNet18 architecture adapted for multi-label classification\n",
    "    \n",
    "    def __init__(self, num_classes=40):\n",
    "        super(ResNet18MultiLabel, self).__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        \n",
    "        # Initial convolution layer for 128x128 images\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Residual layers (ResNet-18 configuration: [2, 2, 2, 2])\n",
    "        self.layer1 = self._make_layer(BasicBlock, 64, 2, stride=1)   # 32x32 -> 32x32\n",
    "        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2)  # 32x32 -> 16x16\n",
    "        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2)  # 16x16 -> 8x8\n",
    "        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2)  # 8x8 -> 4x4\n",
    "        \n",
    "        # Global average pooling and multi-label classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "        # Note: Sigmoid activation will be applied in BCEWithLogitsLoss\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        # Create a residual layer with specified number of blocks\n",
    "        layers = []\n",
    "        \n",
    "        # First block (may downsample)\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        \n",
    "        # Remaining blocks\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        # Initialize weights using He initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Forward pass through the network\n",
    "        \n",
    "        # Initial convolution\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        # Residual layers\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        # Global average pooling and classification\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNet18MultiLabel(num_classes=num_attributes)\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"ResNet18 Multi-Label model created!\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Output classes: {num_attributes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count model parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "num_params = count_parameters(model)\n",
    "print(f\"Total trainable parameters: {num_params:,}\")\n",
    "print(f\"Model size: ~{num_params * 4 / (1024**2):.2f} MB (float32)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Configuration\n",
    "\n",
    "### Hyperparameters Justification:\n",
    "\n",
    "- **Loss Function**: BCEWithLogitsLoss - Combines sigmoid and BCE, numerically stable for multi-label\n",
    "- **Optimizer**: Adam with lr=0.001 - Adaptive learning rate, good for multi-label problems\n",
    "- **Weight Decay**: 1e-4 - L2 regularization to prevent overfitting\n",
    "- **Scheduler**: StepLR - Reduces learning rate every 5 epochs for fine-tuning\n",
    "- **Batch Size**: 128 - Balanced between GPU memory and convergence speed\n",
    "- **Epochs**: 20 - Sufficient for convergence with early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "criterion = nn.BCEWithLogitsLoss()  # For multi-label classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"Loss Function: BCEWithLogitsLoss\")\n",
    "print(f\"Optimizer: Adam (lr=0.001, weight_decay=1e-4)\")\n",
    "print(f\"Scheduler: StepLR (step_size=5, gamma=0.1)\")\n",
    "print(f\"Batch Size: {batch_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    # Train for one epoch\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Move data to device\n",
    "        data = data.to(device)\n",
    "        target = target.to(device).float()\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        running_loss += loss.item()\n",
    "        predictions = torch.sigmoid(output) > 0.5\n",
    "        all_predictions.append(predictions.cpu())\n",
    "        all_targets.append(target.cpu())\n",
    "        \n",
    "        # Print progress\n",
    "        print(f'\\rEpoch {epoch}: [{batch_idx}/{len(train_loader)}] Loss: {loss.item():.4f}', end='', flush=True)\n",
    "    \n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    all_predictions = torch.cat(all_predictions).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    epoch_acc = accuracy_score(all_targets, all_predictions)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "print(\"train_epoch function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    # Validate for one epoch\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            # Move data to device\n",
    "            data = data.to(device)\n",
    "            target = target.to(device).float()\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # Track metrics\n",
    "            val_loss += loss.item()\n",
    "            probs = torch.sigmoid(output)\n",
    "            predictions = probs > 0.5\n",
    "            \n",
    "            all_predictions.append(predictions.cpu())\n",
    "            all_targets.append(target.cpu())\n",
    "            all_probs.append(probs.cpu())\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    val_loss /= len(val_loader)\n",
    "    all_predictions = torch.cat(all_predictions).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    val_acc = accuracy_score(all_targets, all_predictions)\n",
    "    \n",
    "    return val_loss, val_acc, all_predictions, all_targets, all_probs\n",
    "\n",
    "print(\"validate_epoch function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs=20):\n",
    "    # Main training loop with validation\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch + 1)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc, _, _, _ = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f'\\n', '-' * 80)\n",
    "        print(f'\\nEpoch {epoch+1}/{epochs}:')\n",
    "        print(f'  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}')\n",
    "        print(f'  Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n",
    "        print(f'  LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        print('-' * 80)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_celeba_resnet18.pth')\n",
    "            print(f'-'*20, 'Best model saved (Val Acc: {val_acc:.4f})', '-'*20)\n",
    "    \n",
    "    print(\"\\\\nTraining completed!\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accuracies': val_accuracies\n",
    "    }\n",
    "\n",
    "print(\"train_model function defined!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training (80/20 Split)\n",
    "\n",
    "### Training Process:\n",
    "- Training set: 162,770 images (80%)\n",
    "- Validation set: 19,867 images (10%)\n",
    "- Test set: 19,962 images (10%)\n",
    "- 20 epochs with learning rate scheduling\n",
    "- Early stopping based on validation accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(history, save_path='celeba_plots/training_curves.png'):\n",
    "    # Plot training and validation curves\n",
    "    \n",
    "    epochs = range(1, len(history['train_losses']) + 1)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss curves\n",
    "    ax1.plot(epochs, history['train_losses'], 'b-', label='Training Loss', linewidth=2)\n",
    "    ax1.plot(epochs, history['val_losses'], 'r-', label='Validation Loss', linewidth=2)\n",
    "    ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy curves\n",
    "    ax2.plot(epochs, history['train_accuracies'], 'b-', label='Training Accuracy', linewidth=2)\n",
    "    ax2.plot(epochs, history['val_accuracies'], 'r-', label='Validation Accuracy', linewidth=2)\n",
    "    ax2.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print final metrics\n",
    "    print(\"=\"* 50)\n",
    "    print(\"Final Training Results:\")\n",
    "    print(\"=\"* 50)\n",
    "    print(f\"Final Training Loss: {history['train_losses'][-1]:.4f}\")\n",
    "    print(f\"Final Training Accuracy: {history['train_accuracies'][-1]:.4f}\")\n",
    "    print(f\"Final Validation Loss: {history['val_losses'][-1]:.4f}\")\n",
    "    print(f\"Final Validation Accuracy: {history['val_accuracies'][-1]:.4f}\")\n",
    "    print(f\"Best Validation Accuracy: {max(history['val_accuracies']):.4f}\")\n",
    "\n",
    "plot_training_curves(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation\n",
    "\n",
    "### Evaluation Metrics:\n",
    "- **Overall Accuracy**: Percentage of correct predictions across all attributes\n",
    "- **Per-Attribute Accuracy**: Individual accuracy for each of the 40 attributes\n",
    "- **Precision**: True positives / (True positives + False positives)\n",
    "- **Recall**: True positives / (True positives + False negatives)\n",
    "- **F1-Score**: Harmonic mean of precision and recall\n",
    "- **ROC Curves**: For each attribute to visualize true positive vs false positive rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for evaluation\n",
    "model.load_state_dict(torch.load('best_celeba_resnet18.pth'))\n",
    "print(\"Best model loaded for evaluation!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_loss, test_acc, test_preds, test_targets, test_probs = validate_epoch(\n",
    "    model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "print(\"=\"* 50)\n",
    "print(\"Test Set Results:\")\n",
    "print(\"=\"* 50)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Total samples: {len(test_targets)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-attribute metrics\n",
    "def calculate_per_attribute_metrics(predictions, targets, attribute_names):\n",
    "    # Calculate metrics for each attribute\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, attr_name in enumerate(attribute_names):\n",
    "        attr_preds = predictions[:, i]\n",
    "        attr_targets = targets[:, i]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        acc = accuracy_score(attr_targets, attr_preds)\n",
    "        prec = precision_score(attr_targets, attr_preds, zero_division=0)\n",
    "        rec = recall_score(attr_targets, attr_preds, zero_division=0)\n",
    "        f1 = f1_score(attr_targets, attr_preds, zero_division=0)\n",
    "        \n",
    "        results.append({\n",
    "            'Attribute': attr_name,\n",
    "            'Accuracy': acc,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1-Score': f1\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics_df = calculate_per_attribute_metrics(test_preds, test_targets, attribute_names)\n",
    "\n",
    "print(\"\\\\nPer-Attribute Metrics (Top 10 by F1-Score):\")\n",
    "print(metrics_df.sort_values('F1-Score', ascending=False).head(10))\n",
    "\n",
    "print(\"\\\\nPer-Attribute Metrics (Bottom 10 by F1-Score):\")\n",
    "print(metrics_df.sort_values('F1-Score').head(10))\n",
    "\n",
    "# Save metrics\n",
    "metrics_df.to_csv('celeba_per_attribute_metrics.csv', index=False)\n",
    "print(\"\\\\nMetrics saved to celeba_per_attribute_metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize per-attribute performance\n",
    "def plot_attribute_metrics(metrics_df, save_path='celeba_plots/attribute_metrics.png'):\n",
    "    # Plot metrics for all attributes\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(16, 12))\n",
    "    \n",
    "    # Sort by F1-score\n",
    "    metrics_sorted = metrics_df.sort_values('F1-Score', ascending=False)\n",
    "    \n",
    "    # Plot all metrics\n",
    "    x = np.arange(len(metrics_sorted))\n",
    "    width = 0.2\n",
    "    \n",
    "    axes[0].bar(x - 1.5*width, metrics_sorted['Accuracy'], width, label='Accuracy', alpha=0.8)\n",
    "    axes[0].bar(x - 0.5*width, metrics_sorted['Precision'], width, label='Precision', alpha=0.8)\n",
    "    axes[0].bar(x + 0.5*width, metrics_sorted['Recall'], width, label='Recall', alpha=0.8)\n",
    "    axes[0].bar(x + 1.5*width, metrics_sorted['F1-Score'], width, label='F1-Score', alpha=0.8)\n",
    "    \n",
    "    axes[0].set_xlabel('Attributes (sorted by F1-Score)')\n",
    "    axes[0].set_ylabel('Score')\n",
    "    axes[0].set_title('Per-Attribute Performance Metrics', fontweight='bold')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(metrics_sorted['Attribute'], rotation=90, fontsize=7)\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot top 15 attributes by F1-score\n",
    "    top_15 = metrics_sorted.head(15)\n",
    "    x_top = np.arange(len(top_15))\n",
    "    \n",
    "    axes[1].bar(x_top - 1.5*width, top_15['Accuracy'], width, label='Accuracy', alpha=0.8)\n",
    "    axes[1].bar(x_top - 0.5*width, top_15['Precision'], width, label='Precision', alpha=0.8)\n",
    "    axes[1].bar(x_top + 0.5*width, top_15['Recall'], width, label='Recall', alpha=0.8)\n",
    "    axes[1].bar(x_top + 1.5*width, top_15['F1-Score'], width, label='F1-Score', alpha=0.8)\n",
    "    \n",
    "    axes[1].set_xlabel('Top 15 Attributes')\n",
    "    axes[1].set_ylabel('Score')\n",
    "    axes[1].set_title('Top 15 Attributes by F1-Score', fontweight='bold')\n",
    "    axes[1].set_xticks(x_top)\n",
    "    axes[1].set_xticklabels(top_15['Attribute'], rotation=45, ha='right')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_attribute_metrics(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves for selected attributes\n",
    "def plot_roc_curves(targets, probs, attribute_names, selected_attrs=None, save_path='celeba_plots/roc_curves.png'):\n",
    "    # Plot ROC curves for selected attributes\n",
    "    \n",
    "    if selected_attrs is None:\n",
    "        # Select top 9 attributes by F1-score\n",
    "        metrics_df_temp = calculate_per_attribute_metrics(\n",
    "            (probs > 0.5).astype(int), targets, attribute_names\n",
    "        )\n",
    "        selected_attrs = metrics_df_temp.sort_values('F1-Score', ascending=False).head(9)['Attribute'].tolist()\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, attr_name in enumerate(selected_attrs):\n",
    "        attr_idx = attribute_names.index(attr_name)\n",
    "        attr_targets = targets[:, attr_idx]\n",
    "        attr_probs = probs[:, attr_idx]\n",
    "        \n",
    "        # Calculate ROC curve\n",
    "        fpr, tpr, _ = roc_curve(attr_targets, attr_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        # Plot\n",
    "        axes[idx].plot(fpr, tpr, 'b-', linewidth=2, label=f'AUC = {roc_auc:.3f}')\n",
    "        axes[idx].plot([0, 1], [0, 1], 'r--', linewidth=1, label='Random')\n",
    "        axes[idx].set_xlabel('False Positive Rate')\n",
    "        axes[idx].set_ylabel('True Positive Rate')\n",
    "        axes[idx].set_title(f'{attr_name}', fontweight='bold')\n",
    "        axes[idx].legend(loc='lower right')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('ROC Curves for Top 9 Attributes', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curves(test_targets, test_probs, attribute_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for selected attributes\n",
    "def plot_confusion_matrices(predictions, targets, attribute_names, selected_attrs=None, save_path='celeba_plots/confusion_matrices.png'):\n",
    "    # Plot confusion matrices for selected attributes\n",
    "    \n",
    "    if selected_attrs is None:\n",
    "        # Select 6 diverse attributes\n",
    "        selected_attrs = ['Male', 'Smiling', 'Eyeglasses', 'Young', 'Wearing_Hat', 'Attractive']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, attr_name in enumerate(selected_attrs):\n",
    "        attr_idx = attribute_names.index(attr_name)\n",
    "        attr_preds = predictions[:, attr_idx]\n",
    "        attr_targets = targets[:, attr_idx]\n",
    "        \n",
    "        # Calculate confusion matrix\n",
    "        cm = confusion_matrix(attr_targets, attr_preds)\n",
    "        \n",
    "        # Plot\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
    "                   xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "        axes[idx].set_title(attr_name, fontweight='bold')\n",
    "        axes[idx].set_xlabel('Predicted')\n",
    "        axes[idx].set_ylabel('Actual')\n",
    "    \n",
    "    plt.suptitle('Confusion Matrices for Selected Attributes', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrices(test_preds, test_targets, attribute_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cross-Validation (K-Fold)\n",
    "\n",
    "### Cross-Validation Strategy:\n",
    "- 3-Fold cross-validation on training set\n",
    "- Each fold trains a separate model\n",
    "- Averages performance across folds\n",
    "- Provides robust performance estimate\n",
    "- Helps detect overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(train_dataset, device, num_folds=3, epochs=10, batch_size=128):\n",
    "    # Perform k-fold cross-validation\n",
    "    \n",
    "    print(f\"Starting {num_folds}-Fold Cross-Validation...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Create indices for k-fold\n",
    "    dataset_size = len(train_dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_results = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(indices)):\n",
    "        print(f\"\\\\nFold {fold + 1}/{num_folds}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Create data loaders for this fold\n",
    "        train_subset = Subset(train_dataset, train_idx)\n",
    "        val_subset = Subset(train_dataset, val_idx)\n",
    "        \n",
    "        fold_train_loader = DataLoader(train_subset, batch_size=batch_size, \n",
    "                                      shuffle=True, num_workers=2, pin_memory=True)\n",
    "        fold_val_loader = DataLoader(val_subset, batch_size=batch_size, \n",
    "                                    shuffle=False, num_workers=2, pin_memory=True)\n",
    "        \n",
    "        print(f\"Train samples: {len(train_subset)}\")\n",
    "        print(f\"Val samples: {len(val_subset)}\")\n",
    "        \n",
    "        # Create new model for this fold\n",
    "        fold_model = ResNet18MultiLabel(num_classes=num_attributes).to(device)\n",
    "        fold_criterion = nn.BCEWithLogitsLoss()\n",
    "        fold_optimizer = optim.Adam(fold_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "        fold_scheduler = optim.lr_scheduler.StepLR(fold_optimizer, step_size=3, gamma=0.1)\n",
    "        \n",
    "        # Train for this fold\n",
    "        best_val_acc = 0.0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Train\n",
    "            train_loss, train_acc = train_epoch(fold_model, fold_train_loader, \n",
    "                                               fold_criterion, fold_optimizer, device, epoch + 1)\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_acc, _, _, _ = validate_epoch(fold_model, fold_val_loader, \n",
    "                                                        fold_criterion, device)\n",
    "            \n",
    "            fold_scheduler.step()\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{epochs}: Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold + 1,\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'final_train_acc': train_acc,\n",
    "            'final_val_acc': val_acc\n",
    "        })\n",
    "        \n",
    "        print(f\"Fold {fold + 1} Best Val Accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    # Summary\n",
    "    results_df = pd.DataFrame(fold_results)\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\" * 80)\n",
    "    print(\"Cross-Validation Results Summary\")\n",
    "    print(\"=\" * 80)\n",
    "    print(results_df)\n",
    "    print(f\"\\\\nMean Best Val Accuracy: {results_df['best_val_acc'].mean():.4f} ± {results_df['best_val_acc'].std():.4f}\")\n",
    "    print(f\"Mean Final Val Accuracy: {results_df['final_val_acc'].mean():.4f} ± {results_df['final_val_acc'].std():.4f}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "print(\"cross_validate_model function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation (using subset for speed)\n",
    "# Note: Using first 30000 samples for demonstration; use full dataset for production\n",
    "cv_subset = Subset(train_dataset, range(30000))\n",
    "cv_results = cross_validate_model(cv_subset, device, num_folds=3, epochs=5, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Comparison Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary statistics\n",
    "print(\"=\"* 80)\n",
    "print(\"FINAL MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"* 80)\n",
    "print(f\"\\\\nDataset Statistics:\")\n",
    "print(f\"  Training samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "print(f\"  Test samples: {len(test_dataset)}\")\n",
    "print(f\"  Total attributes: {num_attributes}\")\n",
    "\n",
    "print(f\"\\\\nModel Architecture:\")\n",
    "print(f\"  Model: ResNet18 (Multi-Label)\")\n",
    "print(f\"  Parameters: {count_parameters(model):,}\")\n",
    "print(f\"  Input size: 128x128x3\")\n",
    "print(f\"  Output size: {num_attributes}\")\n",
    "\n",
    "print(f\"\\\\nTraining Configuration:\")\n",
    "print(f\"  Loss: BCEWithLogitsLoss\")\n",
    "print(f\"  Optimizer: Adam (lr=0.001, weight_decay=1e-4)\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Epochs trained: {len(history['train_losses'])}\")\n",
    "\n",
    "print(f\"\\\\nPerformance Metrics:\")\n",
    "print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "print(f\"  Mean Attribute F1-Score: {metrics_df['F1-Score'].mean():.4f}\")\n",
    "print(f\"  Best Attribute F1-Score: {metrics_df['F1-Score'].max():.4f}\")\n",
    "print(f\"  Worst Attribute F1-Score: {metrics_df['F1-Score'].min():.4f}\")\n",
    "\n",
    "print(f\"\\\\nTop 5 Performing Attributes:\")\n",
    "top_5_attrs = metrics_df.nlargest(5, 'F1-Score')\n",
    "for _, row in top_5_attrs.iterrows():\n",
    "    print(f\"  {row['Attribute']}: F1={row['F1-Score']:.4f}, Acc={row['Accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\\\nBottom 5 Performing Attributes:\")\n",
    "bottom_5_attrs = metrics_df.nsmallest(5, 'F1-Score')\n",
    "for _, row in bottom_5_attrs.iterrows():\n",
    "    print(f\"  {row['Attribute']}: F1={row['F1-Score']:.4f}, Acc={row['Accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"* 80)\n",
    "print(\"Milestone 2 Complete!\")\n",
    "print(\"=\"* 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final results\n",
    "final_results = {\n",
    "    'test_accuracy': float(test_acc),\n",
    "    'test_loss': float(test_loss),\n",
    "    'mean_f1_score': float(metrics_df['F1-Score'].mean()),\n",
    "    'best_validation_accuracy': float(max(history['val_accuracies'])),\n",
    "    'training_epochs': len(history['train_losses'])\n",
    "}\n",
    "\n",
    "# Save results to file\n",
    "with open('celeba_final_results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "\n",
    "print(\"Results saved to celeba_final_results.json\")\n",
    "print(\"\\\\nAll files saved:\")\n",
    "print(\"  - best_celeba_resnet18.pth (model weights)\")\n",
    "print(\"  - celeba_per_attribute_metrics.csv (detailed metrics)\")\n",
    "print(\"  - celeba_final_results.json (summary results)\")\n",
    "print(\"  - celeba_plots/ (all visualizations)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
