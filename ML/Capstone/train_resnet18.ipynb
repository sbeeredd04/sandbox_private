{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries and Setup"
      ],
      "id": "ba916634"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 Distributed Training Setup"
      ],
      "id": "fe9801aa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def setup_distributed(rank, world_size):\n",
        "    \"\"\"Initialize distributed training environment\"\"\"\n",
        "    os.environ['MASTER_ADDR'] = 'localhost'\n",
        "    os.environ['MASTER_PORT'] = '12355'\n",
        "    \n",
        "    # Initialize the process group\n",
        "    dist.init_process_group(\n",
        "        backend='nccl',  # Use NCCL for GPU training\n",
        "        init_method='env://',\n",
        "        world_size=world_size,\n",
        "        rank=rank\n",
        "    )\n",
        "    torch.cuda.set_device(rank)\n",
        "    print(f\"Rank {rank} initialized on GPU {rank}\")\n",
        "\n",
        "def cleanup_distributed():\n",
        "    \"\"\"Clean up distributed training\"\"\"\n",
        "    if dist.is_initialized():\n",
        "        dist.destroy_process_group()\n",
        "\n",
        "print(\"✓ Distributed helper functions defined\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "e07e171c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Check device availability\n",
        "gpu_ids = \"1,2\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/sbeeredd/miniconda3/envs/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "PyTorch version: 2.1.0+cu118\n"
          ]
        }
      ],
      "id": "4493054f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration"
      ],
      "id": "4759b05a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training configuration\n",
        "image_size = 224\n",
        "batch_size = 512\n",
        "num_workers = 16\n",
        "data_dir = './data'\n",
        "num_epochs = 20\n",
        "learning_rate = 0.001\n",
        "weight_decay = 1e-4\n",
        "\n",
        "# Selected attributes\n",
        "selected_attributes = ['Heavy_Makeup', 'Wearing_Lipstick', 'Attractive', 'High_Cheekbones', 'Rosy_Cheeks']\n",
        "num_attributes = len(selected_attributes)\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Image size: {image_size}x{image_size}\")\n",
        "print(f\"  Batch size: {batch_size}\")\n",
        "print(f\"  Epochs: {num_epochs}\")\n",
        "print(f\"  Learning rate: {learning_rate}\")\n",
        "print(f\"  Attributes: {selected_attributes}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "  Image size: 224x224\n",
            "  Batch size: 512\n",
            "  Epochs: 20\n",
            "  Learning rate: 0.001\n",
            "  Attributes: ['Heavy_Makeup', 'Wearing_Lipstick', 'Attractive', 'High_Cheekbones', 'Rosy_Cheeks']\n"
          ]
        }
      ],
      "id": "7f8a5b32"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Transforms and Loading"
      ],
      "id": "253fb7e1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Data transforms with augmentation for training\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(image_size),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Validation transform (no augmentation)\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "print(\"✓ Data transforms defined\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Data transforms defined\n"
          ]
        }
      ],
      "id": "54542d3d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load CelebA dataset\n",
        "print(\"Loading CelebA dataset...\")\n",
        "\n",
        "try:\n",
        "    train_dataset = datasets.CelebA(\n",
        "        root=data_dir,\n",
        "        split='train',\n",
        "        transform=train_transform,\n",
        "        download=False,\n",
        "        target_type='attr'\n",
        "    )\n",
        "    \n",
        "    val_dataset = datasets.CelebA(\n",
        "        root=data_dir,\n",
        "        split='valid',\n",
        "        transform=val_transform,\n",
        "        download=False,\n",
        "        target_type='attr'\n",
        "    )\n",
        "    \n",
        "    print(f\"✓ Training samples: {len(train_dataset)}\")\n",
        "    print(f\"✓ Validation samples: {len(val_dataset)}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    print(\"Please ensure CelebA dataset is in the data directory\")\n",
        "    raise\n",
        "\n",
        "# Get attribute names and indices\n",
        "attribute_names = [name for name in train_dataset.attr_names if name.strip()]\n",
        "attribute_indices = [attribute_names.index(attr) for attr in selected_attributes]\n",
        "print(f\"\\nAttribute indices: {attribute_indices}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading CelebA dataset...\n",
            "✓ Training samples: 162770\n",
            "✓ Validation samples: 19867\n",
            "\n",
            "Attribute indices: [18, 36, 2, 19, 29]\n"
          ]
        }
      ],
      "id": "9e6e915d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Replace the AttributeFilterDataset cell with this:\n",
        "from dataset import AttributeFilterDataset\n",
        "\n",
        "# Wrap datasets\n",
        "train_dataset = AttributeFilterDataset(train_dataset, attribute_indices)\n",
        "val_dataset = AttributeFilterDataset(val_dataset, attribute_indices)\n",
        "\n",
        "print(\"✓ Dataset filtering applied\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Dataset filtering applied\n"
          ]
        }
      ],
      "id": "40208615"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create DataLoaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True  # Keeps workers alive between epochs\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True\n",
        ")\n",
        "\n",
        "print(f\"✓ DataLoaders created\")\n",
        "print(f\"  Training batches: {len(train_loader)}\")\n",
        "print(f\"  Validation batches: {len(val_loader)}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ DataLoaders created\n",
            "  Training batches: 318\n",
            "  Validation batches: 39\n"
          ]
        }
      ],
      "id": "c48ce2f1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Define ResNet18 Model"
      ],
      "id": "b0435e54"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Basic block for ResNet18\n",
        "class BasicBlock(nn.Module):\n",
        "    \"\"\"Basic residual block with skip connection\"\"\"\n",
        "    \n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        \n",
        "        # First conv layer\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
        "                              stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        # Second conv layer\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                              stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        # Skip connection\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
        "                         stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        \n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        \n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        \n",
        "        out += self.shortcut(identity)\n",
        "        out = self.relu(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "print(\"✓ BasicBlock defined\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ BasicBlock defined\n"
          ]
        }
      ],
      "id": "ed24b34d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ResNet18 for multi-label classification\n",
        "class ResNet18MultiLabel(nn.Module):\n",
        "    \"\"\"ResNet18 architecture for multi-label classification\"\"\"\n",
        "    \n",
        "    def __init__(self, num_classes=5):\n",
        "        super(ResNet18MultiLabel, self).__init__()\n",
        "        \n",
        "        self.in_channels = 64\n",
        "        \n",
        "        # Initial convolution\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "        # ResNet layers (2, 2, 2, 2 blocks)\n",
        "        self.layer1 = self._make_layer(BasicBlock, 64, 2, stride=1)\n",
        "        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2)\n",
        "        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2)\n",
        "        \n",
        "        # Classifier\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "        \n",
        "        # Initialize weights\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "print(\"✓ ResNet18MultiLabel defined\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ ResNet18MultiLabel defined\n"
          ]
        }
      ],
      "id": "f6d44ec8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Create Model and Training Setup"
      ],
      "id": "447ec0c5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create model\n",
        "model = ResNet18MultiLabel(num_classes=num_attributes)\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='max',\n",
        "    factor=0.5,\n",
        "    patience=2,\n",
        "    verbose=True,\n",
        "    min_lr=1e-7\n",
        ")\n",
        "\n",
        "print(f\"✓ Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "print(f\"✓ Loss: BCEWithLogitsLoss\")\n",
        "print(f\"✓ Optimizer: Adam (lr={learning_rate}, weight_decay={weight_decay})\")\n",
        "print(f\"✓ Scheduler: ReduceLROnPlateau\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Model created with 11,179,077 parameters\n",
            "✓ Loss: BCEWithLogitsLoss\n",
            "✓ Optimizer: Adam (lr=0.001, weight_decay=0.0001)\n",
            "✓ Scheduler: ReduceLROnPlateau\n"
          ]
        }
      ],
      "id": "b48f1bc0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Training Functions"
      ],
      "id": "2644a2a4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Start distributed training\n",
        "world_size = torch.cuda.device_count()  # Number of GPUs\n",
        "if world_size < 2:\n",
        "    print(\"Warning: Only 1 GPU detected. DDP works best with 2+ GPUs.\")\n",
        "    print(\"Continuing anyway...\")\n",
        "    world_size = max(1, world_size)\n",
        "\n",
        "print(f\"\\nStarting distributed training on {world_size} GPUs...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Spawn processes for distributed training\n",
        "mp.spawn(\n",
        "    main_worker,\n",
        "    args=(world_size, train_dataset, val_dataset),\n",
        "    nprocs=world_size,\n",
        "    join=True\n",
        ")\n",
        "\n",
        "print(\"\\n✓ All training processes completed!\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ffc0207e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Move to device\n",
        "        data = data.to(device)\n",
        "        target = target.to(device).float()\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track metrics\n",
        "        running_loss += loss.item()\n",
        "        predictions = torch.sigmoid(output) > 0.5\n",
        "        all_predictions.append(predictions.cpu())\n",
        "        all_targets.append(target.cpu())\n",
        "\n",
        "        # Progress\n",
        "        print(f'\\rEpoch {epoch}: [{batch_idx+1}/{len(train_loader)}] Loss: {loss.item():.4f}', end='', flush=True)\n",
        "\n",
        "    # Calculate metrics\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    all_predictions = torch.cat(all_predictions).numpy()\n",
        "    all_targets = torch.cat(all_targets).numpy()\n",
        "    epoch_acc = (all_predictions == all_targets).mean()\n",
        "\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "print(\"✓ train_epoch function defined\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ train_epoch function defined\n"
          ]
        }
      ],
      "id": "16afe935"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def validate_epoch(model, val_loader, criterion, device):\n",
        "    \"\"\"Validate the model\"\"\"\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device).float()\n",
        "\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            predictions = torch.sigmoid(output) > 0.5\n",
        "            all_predictions.append(predictions.cpu())\n",
        "            all_targets.append(target.cpu())\n",
        "\n",
        "    # Calculate metrics\n",
        "    val_loss /= len(val_loader)\n",
        "    all_predictions = torch.cat(all_predictions).numpy()\n",
        "    all_targets = torch.cat(all_targets).numpy()\n",
        "    val_acc = (all_predictions == all_targets).mean()\n",
        "\n",
        "    return val_loss, val_acc\n",
        "\n",
        "print(\"✓ validate_epoch function defined\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ validate_epoch function defined\n"
          ]
        }
      ],
      "id": "46e57f0c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train the Model"
      ],
      "id": "8daffad3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training loop\n",
        "print(\"\\nStarting training...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # Train\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    \n",
        "    # Validate\n",
        "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
        "    \n",
        "    # Update scheduler\n",
        "    scheduler.step(val_acc)\n",
        "    \n",
        "    # Store metrics\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "    \n",
        "    # Print epoch summary\n",
        "    print(f'\\n{\"-\"*80}')\n",
        "    print(f'Epoch {epoch}/{num_epochs}:')\n",
        "    print(f'  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}')\n",
        "    print(f'  Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n",
        "    print(f'  LR: {optimizer.param_groups[0][\"lr \"]:.6f}')\n",
        "    print(f'{\"-\"*80}')\n",
        "    \n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), 'best_celeba_resnet18.pth')\n",
        "        print(f'  ✓ New best model saved with Val Acc: {best_val_acc:.4f}')\n",
        "        \n",
        "print(\"Training complete.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training...\n",
            "================================================================================\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 21.97 GiB of which 36.50 MiB is free. Process 3374839 has 17.17 GiB memory in use. Including non-PyTorch memory, this process has 4.76 GiB memory in use. Of the allocated memory 4.54 GiB is allocated by PyTorch, and 21.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m best_val_acc = \u001b[32m0.0\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, num_epochs + \u001b[32m1\u001b[39m):\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     train_loss, train_acc = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m     16\u001b[39m     val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, train_loader, criterion, optimizer, device, epoch)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m     14\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m loss = criterion(output, target)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1525\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1526\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1530\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mResNet18MultiLabel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     51\u001b[39m x = \u001b[38;5;28mself\u001b[39m.relu(x)\n\u001b[32m     52\u001b[39m x = \u001b[38;5;28mself\u001b[39m.maxpool(x)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m x = \u001b[38;5;28mself\u001b[39m.layer2(x)\n\u001b[32m     56\u001b[39m x = \u001b[38;5;28mself\u001b[39m.layer3(x)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1525\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1526\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1530\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1525\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1526\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1530\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mBasicBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     32\u001b[39m     identity = x\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.bn1(out)\n\u001b[32m     36\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.relu(out)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1525\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1526\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1530\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m'\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    453\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(F.pad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode),\n\u001b[32m    454\u001b[39m                     weight, bias, \u001b[38;5;28mself\u001b[39m.stride,\n\u001b[32m    455\u001b[39m                     _pair(\u001b[32m0\u001b[39m), \u001b[38;5;28mself\u001b[39m.dilation, \u001b[38;5;28mself\u001b[39m.groups)\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 21.97 GiB of which 36.50 MiB is free. Process 3374839 has 17.17 GiB memory in use. Including non-PyTorch memory, this process has 4.76 GiB memory in use. Of the allocated memory 4.54 GiB is allocated by PyTorch, and 21.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "id": "2c17180d"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}